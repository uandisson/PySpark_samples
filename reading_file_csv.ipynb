{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeEplacszaws"
      },
      "source": [
        "# Uandisson Miranda\n",
        "[@uandisson](https://github.com/uandisson)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MslWWw1hUMNH"
      },
      "source": [
        "# Installing [Spark](https://spark.apache.org/downloads.html) and Java\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nqheTdlMK6k"
      },
      "source": [
        "!sudo apt-get update    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcyZOeAjMvCy"
      },
      "source": [
        "!sudo apt-get upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePMYToeUK3YJ"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null #JAVA 8 install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "znwg0RkqBKX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tar"
      ],
      "metadata": {
        "id": "EKh0F7dJDm0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xzvf /content/spark-3.3.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "7EguHXaaA1ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7YsET8XXWw"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" #configure JAVA path\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"#configure SPARK path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SaaYfdydhdd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxevSK1DtcEi"
      },
      "source": [
        "!ls  #file list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wlMX6sf6_JP"
      },
      "source": [
        "##Installing FindSpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U6RQzQeXN2x"
      },
      "source": [
        "!pip install -q findspark #install findspark, to find SPARK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DumOw9koMBSL"
      },
      "source": [
        "# make pyspark \"importable\"\n",
        "import findspark #import findspark library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export SPARK_HOME=/opt/spark-3.3.1-bin-hadoop3"
      ],
      "metadata": {
        "id": "lYhl3Jn0hv-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "tMnhW_MUg0rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7au9zYsU7hw"
      },
      "source": [
        "##Importing PySpark Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czunoPnnVHka"
      },
      "source": [
        "%time \n",
        "#imports for SPARK and its libraries\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext, SparkSession\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCgXRDFeA59"
      },
      "source": [
        "%time \n",
        "#creates 4 variables: session, context, sql, streaming\n",
        "ss = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
        "sql_sc = SQLContext(sc)\n",
        "ssc = StreamingContext(sc, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jEzao-rsVl_"
      },
      "source": [
        "%time \n",
        "#imports for additional python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopy.distance as gp\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "import pyarrow as pa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFXG7QvJgr72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV file examples\n",
        "\n",
        "[CSV Files](https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html)\n",
        "\n",
        "CSV is a data directory which contains examples of CSV files, a flat file format describing values in a table.\n",
        "\n"
      ],
      "metadata": {
        "id": "mad4Sgbegyp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://people.sc.fsu.edu/~jburkardt/data/csv/airtravel.csv"
      ],
      "metadata": {
        "id": "JCrbA9vPgo9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone the files, from github\n",
        "\n",
        "#%time\n",
        "#! git clone https://github.com/uandisson/project_folder_name"
      ],
      "metadata": {
        "id": "0hEhDWfNjdTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaFxma2gm55i"
      },
      "source": [
        "#Reading CSV file with PySprak"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA-E7sWGm18z"
      },
      "source": [
        "import time\n",
        "%time \n",
        "start = time.time()\n",
        "\n",
        "path_file_sample = '/content/airtravel.csv'\n",
        "\n",
        "df_file_sample_csv = ss.read.csv(path_file_sample, header=True) # s3 , cloud storage gcp. bucket Azure\n",
        "\n",
        "print('seconds: {}'.format(time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open(path_file_sample).read()"
      ],
      "metadata": {
        "id": "jMCrRajiu5Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_file_sample_csv"
      ],
      "metadata": {
        "id": "08T0tqlfaHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw1UkommrJva"
      },
      "source": [
        "columns = df_file_sample_csv.columns\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_file_sample_csv.schema"
      ],
      "metadata": {
        "id": "eG74_MrbUmg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRINjDgGrx3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in columns[1:]:\n",
        "  new_name = str(col).strip().replace('\"', '')\n",
        "  df_file_sample_csv = df_file_sample_csv.withColumnRenamed(col,f\"year_{new_name}\")\n",
        "\n",
        "df_file_sample_csv.printSchema()"
      ],
      "metadata": {
        "id": "cRXI2EqGqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35C6ESlcrM3v"
      },
      "source": [
        "df_file_sample_csv.createOrReplaceTempView('view')\n",
        "df_file_sample_csv.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoTflVySt3TH"
      },
      "source": [
        "sql_df = sql_sc.sql(\"SELECT month FROM view\")\n",
        "sql_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_df = sql_sc.sql(f\"SELECT month, year_1958 FROM view WHERE  year_1958 > 500\")\n",
        "sql_df.show()"
      ],
      "metadata": {
        "id": "W7Wb8clYUGcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}